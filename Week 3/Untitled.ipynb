{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If number of columns are very high. Divide the dataset into different logical category \n",
    "like Numerical, Categorical, Nominal, Ordinal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Linear Regression\n",
    "Regression is a combination of several Features.\n",
    "f - Features\n",
    "w - Constants\n",
    "\n",
    "y = w0 + w1f1 + w2f2 + w3f3 .....\n",
    "\n",
    "Which is non-linear combination\n",
    "w0 + sin(f1) + e(f2) + w3(3)f3 + .... \n",
    "Here sin(f1) is a feature that is created and all others.\n",
    "\n",
    "Which is linear combination\n",
    "w0 + f1(2)*w1 + f2(3)*(w1+w2) + .... \n",
    "Here f1(2) is a feature that is created and all others."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "This will give a Categorical value. It lies beyond Linear regression, after applying Linear Regression it applies Signoid function to make value categorical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Simple classification/complexity problems can be solved using Linear Regression or Logistic Regression,\n",
    "But when there is a Moderate complexity than we need to use advance algorithms like Random Forest, SVM.\n",
    "\n",
    "For Extreme complexity we use Deep Networks. \n",
    "Universal functional Combinator\n",
    "When any Mathematical function came as a input to Logical Regression thenn apply Sigmoid (Logistic). Output of this is an Activation or input to Another Node that is another Logistic Regression and output of it is Non-Linear Combination.\n",
    "Here Node is Logistic Regression (which is combination of Linear regression(Linear Functions) and apply Sigmoid to it to get Classified value i.e. 0 or 1)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mechanics of Neural Network\n",
    "Inputs - Features of a Dataset\n",
    "Activation - Output of Linear Regression is input for Sigmoid\n",
    "Output - Prediction\n",
    "\n",
    "We are given a Supervised data, we pick Features for predicting the Output\n",
    "Process has 2 pass - Forward, Backward Pass\n",
    "\n",
    "Forward Pass\n",
    "We apply all Input to Neural Net (Combination of Nodes(Linear and Logistic Regression)) and we get Output (Output of 1 row is called Loss).\n",
    "For whole dataset we add Loss = Cost.\n",
    "In forward pass, there is a Neural Net (which is a combination of Affime and Activation)\n",
    "Affime - Linear Regression for Features/Input\n",
    "Activation - Output of Affime, apply as input to Logistic Regression and it makes Output in 0 or 1.\n",
    "\n",
    "Backward Pass\n",
    "Loss of 1 data row goes backward to Neural net and according to that Cost, whole neural net adjust there Constant value so that for next DataRow Cost should come optimum.\n",
    "Backward pass does 3 thinfs - BackPropogation than Gradient Decent than Update\n",
    "BackPropogation - Go through complete Neural Net Backwards\n",
    "Gradient Decent - Calculate Constant(w) to be adjusted on each Affime (Linear Regression) for every Node in Neural Net\n",
    "Update          - Update the Costant(w) to each Affime. \n",
    "\n",
    "Epoch - Forward and Backward pass for 1 DataSet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Normalization = (f1 - mean(f1)) / Sigma(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
